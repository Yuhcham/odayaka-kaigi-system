"""

# app.py
import os
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

# --- Flaskã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
app = Flask(__name__)

# --- OpenAI APIã‚­ãƒ¼ã®è¨­å®š ---
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ã‹ã€ç›´æ¥å…¥åŠ›ã•ã›ã‚‹
# ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ãŸã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å…¥åŠ›ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    # å®Ÿéš›ã«ã¯ã“ã“ã§çµ‚äº†ã™ã‚‹å‡¦ç†ã‚’å…¥ã‚Œã‚‹ã¹ãã§ã™ãŒã€ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«é€²ã‚ã¾ã™
    client = None

# --- ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/')
def index():
    # index.html ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã«è¡¨ç¤ºã™ã‚‹
    return render_template('index.html')

# --- éŸ³å£°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client:
        return jsonify({'error': 'OpenAI client is not configured.'}), 500

    # Webãƒšãƒ¼ã‚¸ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚‹
    if 'audio' not in request.files:
        return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']

    if audio_file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    try:
        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja"
        )
        result_text = transcript.text
        print(f"æ–‡å­—èµ·ã“ã—çµæœ: {result_text}") # ã‚µãƒ¼ãƒãƒ¼ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤º

        # ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®š
        ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
        is_negative = False
        for word in ng_words:
            if word in result_text:
                is_negative = True
                break
        
        # åˆ¤å®šçµæœã‚’Webãƒšãƒ¼ã‚¸ã«è¿”ã™ (JSONå½¢å¼)
        return jsonify({'is_negative': is_negative, 'text': result_text})

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# --- ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• ---
if __name__ == '__main__':
    # debug=True ã«ã™ã‚‹ã¨ã€ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã—ãŸéš›ã«è‡ªå‹•ã§ã‚µãƒ¼ãƒãƒ¼ãŒå†èµ·å‹•ã—ã¦ä¾¿åˆ©
    app.run(debug=True)

"""

"""ç„¡ç™ºè©±ç¢ºç‡ã€å¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å®Ÿè£…â†“ï¼ˆdotã‚’ã€Œã€ã«ã—ã¦å¤±æ•—ï¼‰

# app.py (AIå¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½æ­è¼‰ æœ€çµ‚ç‰ˆ)
import os
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

# --- Flaskã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
app = Flask(__name__)

# --- OpenAI APIã‚­ãƒ¼ã®è¨­å®š ---
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    client = None

# --- ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/')
def index():
    return render_template('index.html')

# --- éŸ³å£°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client:
        return jsonify({'error': 'OpenAI client is not configured.'}), 500

    if 'audio' not in request.files:
        return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']

    if audio_file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    try:
        # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒAIã¨ã®å¯¾è©±ã®é€²åŒ–éƒ¨åˆ† â˜…â˜…â˜… ---

        # ä¼šè­°ã®æ–‡è„ˆã«åˆã‚ã›ãŸãƒ’ãƒ³ãƒˆã‚’å®šç¾©
        prompt_text = "ç©ã‚„ã‹ä¼šè­°ã‚·ã‚¹ãƒ†ãƒ ã€Flaskã€Pythonã€APIã€UIã€UXã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‚ä»•æ§˜å¤‰æ›´ã€‚ãƒ‡ãƒãƒƒã‚°ã€‚ã‚¨ãƒ©ãƒ¼ã€‚ã‚µãƒ¼ãƒãƒ¼ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€‚ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€‚"

        # verbose_jsonå½¢å¼ã§ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’AIã«è¦æ±‚ã™ã‚‹
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json" # è©³ç´°ãªæƒ…å ±ã‚’è¦æ±‚ï¼
        )

        # --- å¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®ãƒ­ã‚¸ãƒƒã‚¯ ---
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®ãŸã‚ã®è¨­å®šå€¤
        LOGPROB_THRESHOLD = -1.0  # è‡ªä¿¡ã‚¹ã‚³ã‚¢ã®ã—ãã„å€¤
        NO_SPEECH_PROB_THRESHOLD = 0.6  # ç„¡ç™ºè©±ç¢ºç‡ã®ã—ãã„å€¤

        filtered_text = ""
        # AIã‹ã‚‰ã®è¿”äº‹ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆåŒºåˆ‡ã‚Šï¼‰ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
        for segment in transcript_data["segments"]:
            avg_logprob = segment["avg_logprob"]
            no_speech_prob = segment["no_speech_prob"]
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«æƒ…å ±ã‚’è¡¨ç¤º
            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment['text']}', è‡ªä¿¡ã‚¹ã‚³ã‚¢: {avg_logprob:.2f}, ç„¡ç™ºè©±ç¢ºç‡: {no_speech_prob:.2f}")

            # è‡ªä¿¡ã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹ã‹ã€ç„¡ç™ºè©±ç¢ºç‡ãŒé«˜ã™ãã‚‹å ´åˆã¯ã€ãã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç„¡è¦–ã™ã‚‹
            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                print(" -> å¹»è´ã¨åˆ¤æ–­ã—ã€ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                continue # æ¬¡ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¸
            
            # å•é¡Œãªã‘ã‚Œã°ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            filtered_text += segment["text"]
        
        # --- ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã§è¡Œã† ---
        is_negative = False
        if filtered_text: # ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿åˆ¤å®š
            ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
            for word in ng_words:
                if word in filtered_text:
                    is_negative = True
                    break
        
        # åˆ¤å®šçµæœã‚’Webãƒšãƒ¼ã‚¸ã«è¿”ã™
        return jsonify({'is_negative': is_negative, 'text': filtered_text})

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# --- ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• ---
if __name__ == '__main__':
    app.run(debug=True)

"""
"""
ç„¡ç™ºè©±ç¢ºç‡ãŒç”˜ã„
# app.py (ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œ æœ€çµ‚ç‰ˆ)
import os
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

# --- Flaskã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
app = Flask(__name__)

# --- OpenAI APIã‚­ãƒ¼ã®è¨­å®š ---
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    client = None

# --- ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/')
def index():
    return render_template('index.html')

# --- éŸ³å£°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client:
        return jsonify({'error': 'OpenAI client is not configured.'}), 500

    if 'audio' not in request.files:
        return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']

    if audio_file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    try:
        # ä¼šè­°ã®æ–‡è„ˆã«åˆã‚ã›ãŸãƒ’ãƒ³ãƒˆã‚’å®šç¾©
        prompt_text = "ç©ã‚„ã‹ä¼šè­°ã‚·ã‚¹ãƒ†ãƒ ã€Flaskã€Pythonã€APIã€UIã€UXã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€‚ä»•æ§˜å¤‰æ›´ã€‚ãƒ‡ãƒãƒƒã‚°ã€‚ã‚¨ãƒ©ãƒ¼ã€‚ã‚µãƒ¼ãƒãƒ¼ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€‚ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€‚ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€‚"

        # verbose_jsonå½¢å¼ã§ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’AIã«è¦æ±‚ã™ã‚‹
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )

        # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â˜…â˜…â˜… ---
        # --- å¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®ãƒ­ã‚¸ãƒƒã‚¯ ---
        LOGPROB_THRESHOLD = -1.0
        NO_SPEECH_PROB_THRESHOLD = 0.6

        filtered_text = ""
        # '[]'ã§ã¯ãªã'.'ã§ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            
            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment.text}', è‡ªä¿¡ã‚¹ã‚³ã‚¢: {avg_logprob:.2f}, ç„¡ç™ºè©±ç¢ºç‡: {no_speech_prob:.2f}")

            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                print(" -> å¹»è´ã¨åˆ¤æ–­ã—ã€ã“ã®ç™ºè¨€ã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                continue
            
            filtered_text += segment.text
        
        # --- ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã§è¡Œã† ---
        is_negative = False
        if filtered_text:
            ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
            for word in ng_words:
                if word in filtered_text:
                    is_negative = True
                    break
        
        # '[]'ã§ã¯ãªã'.'ã§å…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
        # ãŸã ã—ã€ä»Šå›ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã†ã®ã§ã€transcript_data.textã¯ä½¿ã‚ãªã„
        return jsonify({'is_negative': is_negative, 'text': filtered_text})

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# --- ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• ---
if __name__ == '__main__':
    app.run(debug=True)

"""
"""
# app.py (æœ€çµ‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆ)
import os
import math # æŒ‡æ•°è¨ˆç®—ã®ãŸã‚ã«mathãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

# --- Flaskã‚¢ãƒ—ãƒªã®åˆæœŸè¨­å®š ---
app = Flask(__name__)

# --- OpenAI APIã‚­ãƒ¼ã®è¨­å®š ---
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    client = None

# --- ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/')
def index():
    return render_template('index.html')

# --- éŸ³å£°åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ãƒ«ãƒ¼ãƒˆ ---
@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client:
        return jsonify({'error': 'OpenAI client is not configured.'}), 500

    if 'audio' not in request.files:
        return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']

    if audio_file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    try:
        # ä¼šè­°ã®æ–‡è„ˆã«åˆã‚ã›ãŸãƒ’ãƒ³ãƒˆã‚’å®šç¾©
        prompt_text = ""

        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )

        # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°éƒ¨åˆ† â˜…â˜…â˜… ---
        
        # 1. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°åŸºæº–ã‚’ã‚ˆã‚Šå³ã—ãè¨­å®š
        # è‡ªä¿¡ã‚¹ã‚³ã‚¢ã®ã—ãã„å€¤ã€‚-1.0ã‹ã‚‰-0.6ã¸ï¼ˆ0ã«è¿‘ã„ã»ã©å³ã—ã„ï¼‰
        LOGPROB_THRESHOLD = -0.6
        # ç„¡ç™ºè©±ç¢ºç‡ã®ã—ãã„å€¤ã€‚0.6ã‹ã‚‰0.4ã¸ï¼ˆä½ã„ã»ã©å³ã—ã„ï¼‰
        NO_SPEECH_PROB_THRESHOLD = 0.4

        filtered_text = ""
        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            
            # 2. ã‚¹ã‚³ã‚¢ã‚’ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã«å¤‰æ›ã—ã¦ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«åˆ†ã‹ã‚Šã‚„ã™ãè¡¨ç¤º
            # è‡ªä¿¡ã‚¹ã‚³ã‚¢ã¯ã€exp(logprob)ã§ç¢ºç‡ã«å¤‰æ›ã§ãã‚‹
            confidence_percent = math.exp(avg_logprob) * 100
            no_speech_percent = no_speech_prob * 100
            
            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment.text}', è‡ªä¿¡: {confidence_percent:.1f}%, ç„¡ç™ºè©±ç¢ºç‡: {no_speech_percent:.1f}%")

            # å³ã—ããªã£ãŸåŸºæº–ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                print(" -> å¹»è´ã¨åˆ¤æ–­ã—ã€ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                continue
            
            filtered_text += segment.text
        
        is_negative = False
        if filtered_text:
            ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
            for word in ng_words:
                if word in filtered_text:
                    is_negative = True
                    break
        
        return jsonify({'is_negative': is_negative, 'text': filtered_text})

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# --- ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹• ---
if __name__ == '__main__':
    app.run(debug=True)

æ¬¡ã«ã€LLMã‚’å®Ÿè£…ã—ã¾ã™ï¼
"""


"""
# app.py (åˆ†æã‚¹ã‚³ã‚¢è¡¨ç¤ºå¯¾å¿œç‰ˆ)
import os
import math
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )
        
        LOGPROB_THRESHOLD = -0.6
        NO_SPEECH_PROB_THRESHOLD = 0.4

        filtered_text = ""
        # --- â˜…â˜…â˜… ç™ºè¨€å…¨ä½“ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆã‚’è¿½åŠ  â˜…â˜…â˜… ---
        valid_confidences = []
        valid_no_speech_probs = []

        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            
            confidence_percent = math.exp(avg_logprob) * 100
            no_speech_percent = no_speech_prob * 100
            
            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment.text}', è‡ªä¿¡: {confidence_percent:.1f}%, ç„¡ç™ºè©±ç¢ºç‡: {no_speech_percent:.1f}%")

            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                print(" -> å¹»è´ã¨åˆ¤æ–­ã—ã€ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                continue
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é€šéã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã‚¹ã‚³ã‚¢ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            valid_confidences.append(confidence_percent)
            valid_no_speech_probs.append(no_speech_percent)
            filtered_text += segment.text
        
        # --- â˜…â˜…â˜… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— â˜…â˜…â˜… ---
        avg_confidence = sum(valid_confidences) / len(valid_confidences) if valid_confidences else 0
        avg_no_speech_prob = sum(valid_no_speech_probs) / len(valid_no_speech_probs) if valid_no_speech_probs else 0

        is_negative = False
        if filtered_text:
            ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
            for word in ng_words:
                if word in filtered_text:
                    is_negative = True
                    break
        
        # --- â˜…â˜…â˜… JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ  â˜…â˜…â˜… ---
        return jsonify({
            'is_negative': is_negative,
            'text': filtered_text,
            'confidence': f"{avg_confidence:.1f}",
            'no_speech_prob': f"{avg_no_speech_prob:.1f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
"""
"""
# app.py (LLMæ ¡æ­£æ©Ÿèƒ½ + å…¨æ©Ÿèƒ½æ­è¼‰ æœ€çµ‚ç‰ˆ)
import os
import math
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )
        
        LOGPROB_THRESHOLD = -1.0
        NO_SPEECH_PROB_THRESHOLD = 0.7

        filtered_text = ""
        segments_for_display = []

        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            confidence_percent = math.exp(avg_logprob) * 100
            no_speech_percent = no_speech_prob * 100
            
            segments_for_display.append({
                "text": segment.text,
                "confidence": f"{confidence_percent:.1f}",
                "no_speech_prob": f"{no_speech_percent:.1f}"
            })

            print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: '{segment.text}', è‡ªä¿¡: {confidence_percent:.1f}%, ç„¡ç™ºè©±ç¢ºç‡: {no_speech_percent:.1f}%")

            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                print(" -> å¹»è´ã¨åˆ¤æ–­ã—ã€ã“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                continue
            
            filtered_text += segment.text
        
        is_negative = False
        if filtered_text:
            ng_words = ["ãƒ€ãƒ¡ã ", "æœ€æ‚ª", "è©±ã«ãªã‚‰ãªã„", "çµ¶å¯¾ã«"]
            for word in ng_words:
                if word in filtered_text:
                    is_negative = True
                    break
        
        return jsonify({
            'is_negative': is_negative,
            'filtered_text': filtered_text,
            'raw_segments': segments_for_display
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# --- LLMã«æ ¡æ­£ã‚’ä¾é ¼ã™ã‚‹æ–°ã—ã„ãƒ«ãƒ¼ãƒˆ ---
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client:
        return jsonify({'error': 'OpenAI client is not configured.'}), 500
    
    data = request.json
    if not data or 'text' not in data:
        return jsonify({'error': 'No text provided for correction.'}), 400

    original_text = data['text']

    try:
        # GPTãƒ¢ãƒ‡ãƒ«ã«æ ¡æ­£ã‚’ä¾é ¼
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯ã€ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªæ›¸è¨˜ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ï¼ˆä¾‹ï¼šã€Œå¤©å€™ã‚’ã¨ã‚Šã¾ã™ã€â†’ã€Œç‚¹å‘¼ã‚’ã¨ã‚Šã¾ã™ã€ï¼‰ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user",
                    "content": original_text
                }
            ]
        )
        
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})

    except Exception as e:
        print(f"LLMæ ¡æ­£ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)


"""
"""
# app.py (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†ææ­è¼‰ æœ€çµ‚ç‰ˆ)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:


        # --- AI â‘ ï¼šWhisperã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã— ---
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )
        
        # --- å¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
        LOGPROB_THRESHOLD = -1.0
        NO_SPEECH_PROB_THRESHOLD = 0.7
        filtered_text = ""
        segments_for_display = []
        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                continue
            filtered_text += segment.text
            segments_for_display.append({
                "text": segment.text,
                "confidence": f"{math.exp(avg_logprob) * 100:.1f}",
                "no_speech_prob": f"{no_speech_prob * 100:.1f}"
            })
        
        # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒæ–°ã—ã„å‡¦ç† â˜…â˜…â˜… ---
        # --- AI â‘¡ï¼šLLMã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†æ ---
        sentiment_score = 0.0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        is_negative_atmosphere = False

        if filtered_text.strip(): # æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚‹å ´åˆã®ã¿æ„Ÿæƒ…åˆ†æ
            try:
                # Function Callingã‚’ä½¿ã£ã¦ã€æ„Ÿæƒ…ã‚’æ•°å€¤ã§å–å¾—ã™ã‚‹
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": filtered_text}
                    ],
                    functions=[
                        {
                            "name": "set_sentiment_score",
                            "description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "score": {
                                        "type": "number",
                                        "description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"
                                    }
                                },
                                "required": ["score"]
                            }
                        }
                    ],
                    function_call={"name": "set_sentiment_score"}
                )
                
                # AIã‹ã‚‰ã®è¿”äº‹ã‚’è§£æ
                import json
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                sentiment_score = function_args.get("score", 0.0)
                
                # é›°å›²æ°—ãŒãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹ã®åˆ¤å®šï¼ˆ-0.3ã‚ˆã‚Šä½ã„å ´åˆï¼‰
                if sentiment_score < -0.3:
                    is_negative_atmosphere = True

            except Exception as e:
                print(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                # æ„Ÿæƒ…åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¦ã‚‚ã€æ–‡å­—èµ·ã“ã—ã¯ç¶šã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹

        # is_negativeã‚’is_negative_atmosphereã«ç½®ãæ›ãˆ
        return jsonify({
            'is_negative': is_negative_atmosphere, 
            'filtered_text': filtered_text,
            'raw_segments': segments_for_display,
            'sentiment_score': f"{sentiment_score:.2f}" # æ–°ã—ãæ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# /correct ãƒ«ãƒ¼ãƒˆã¨ main ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)


"""
"""
éŸ³å£°å–ã‚Šè¾¼ã¿ã‚¨ãƒ©ãƒ¼
# app.py (librosaã«ã‚ˆã‚‹ãƒˆãƒ¼ãƒ³åˆ†ææ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸæœ€æ–°ç‰ˆ)
import os
import math
import librosa  # â˜…è¿½åŠ 
import numpy as np # â˜…è¿½åŠ 
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        # --- â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒãƒˆãƒ¼ãƒ³åˆ†æã®æ–°ã—ã„å‡¦ç† â˜…â˜…â˜… ---

        # 1. ä¸€æ™‚çš„ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ (librosaã§èª­ã¿è¾¼ã‚€ãŸã‚)
        temp_filename = "temp_audio_for_librosa.webm"
        audio_file.save(temp_filename)

        # 2. librosaã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        # y: éŸ³å£°ã®æ³¢å½¢ãƒ‡ãƒ¼ã‚¿, sr: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
        y, sr = librosa.load(temp_filename)

        # 3. éŸ³éŸ¿ç‰¹å¾´é‡ã‚’æŠ½å‡º
        # ãƒ”ãƒƒãƒï¼ˆå£°ã®é«˜ã•ï¼‰ã‚’æ¨å®š
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆå£°ã®å¤§ãã•ï¼‰ã‚’è¨ˆç®—
        rms = librosa.feature.rms(y=y)

        # 4. ç‰¹å¾´é‡ã‚’ä»£è¡¨çš„ãªæ•°å€¤ã«å¤‰æ›ï¼ˆå¹³å‡å€¤ã‚’ã¨ã‚‹ï¼‰
        # ç™ºè©±åŒºé–“ã ã‘ã®å¹³å‡ãƒ”ãƒƒãƒã‚’è¨ˆç®— (0ã‚ˆã‚Šå¤§ãã„å€¤ã®ã¿)
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0
        # å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
        rms_mean = np.mean(rms)

        # 5. çµæœã‚’ã‚µãƒ¼ãƒãƒ¼ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã—ã¦ç¢ºèª
        print("--- ğŸ¶ ãƒˆãƒ¼ãƒ³åˆ†æ ä¸­é–“çµæœ ğŸ¶ ---")
        print(f"å¹³å‡ãƒ”ãƒƒãƒ (å£°ã®é«˜ã•): {pitch_mean:.2f}")
        print(f"å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼ (å£°ã®å¤§ãã•): {rms_mean:.2f}")
        print("-----------------------------------")
        
        # --- â˜…â˜…â˜… ãƒˆãƒ¼ãƒ³åˆ†æã¯ã“ã“ã¾ã§ â˜…â˜…â˜… ---
        # ã“ã®å¾Œã€ã“ã‚Œã¾ã§é€šã‚ŠWhisper APIã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¡ã™ãŸã‚ã€
        # audio_fileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
        audio_file.seek(0)


        # --- AI â‘ ï¼šWhisperã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã— (æ—¢å­˜ã®å‡¦ç†) ---
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )
        
        # --- å¹»è´ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
        LOGPROB_THRESHOLD = -1.0
        NO_SPEECH_PROB_THRESHOLD = 0.7
        filtered_text = ""
        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                continue
            filtered_text += segment.text
        
        # --- AI â‘¡ï¼šLLMã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„Ÿæƒ…åˆ†æ ---
        sentiment_score = 0.0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        is_negative_atmosphere = False

        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": filtered_text}
                    ],
                    functions=[
                        {
                            "name": "set_sentiment_score",
                            "description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "score": {
                                        "type": "number",
                                        "description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"
                                    }
                                },
                                "required": ["score"]
                            }
                        }
                    ],
                    function_call={"name": "set_sentiment_score"}
                )
                
                import json
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                sentiment_score = function_args.get("score", 0.0)
                
                if sentiment_score < -0.3:
                    is_negative_atmosphere = True

            except Exception as e:
                print(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return jsonify({
            'is_negative': is_negative_atmosphere, 
            'filtered_text': filtered_text,
            'sentiment_score': f"{sentiment_score:.2f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# /correct ãƒ«ãƒ¼ãƒˆã¨ main ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

"""
"""
# app.py (pydubã«ã‚ˆã‚‹å¤‰æ›æ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸæœ€çµ‚è§£æ±ºç‰ˆ)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass
from pydub import AudioSegment # â˜…pydubã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        # --- â˜…â˜…â˜… ãƒˆãƒ¼ãƒ³åˆ†æã®å‡¦ç†ã‚’pydubã‚’ä½¿ã£ã¦ä¿®æ­£ â˜…â˜…â˜… ---

        # 1. ä¸€æ™‚çš„ã«webmãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        webm_filename = "temp_audio.webm"
        audio_file.save(webm_filename)

        # 2. pydubã‚’ä½¿ã£ã¦webmãƒ•ã‚¡ã‚¤ãƒ«ã‚’wavãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›
        sound = AudioSegment.from_file(webm_filename, format="webm")
        wav_filename = "temp_converted.wav"
        sound.export(wav_filename, format="wav")

        # 3. librosaã§ã€Œå¤‰æ›å¾Œã®wavãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚’èª­ã¿è¾¼ã¿
        y, sr = librosa.load(wav_filename)

        # 4. éŸ³éŸ¿ç‰¹å¾´é‡ã‚’æŠ½å‡º
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
        rms = librosa.feature.rms(y=y)

        # 5. ç‰¹å¾´é‡ã‚’ä»£è¡¨çš„ãªæ•°å€¤ã«å¤‰æ›
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0
        rms_mean = np.mean(rms)

        # 6. çµæœã‚’ã‚µãƒ¼ãƒãƒ¼ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã—ã¦ç¢ºèª
        print("--- ğŸ¶ ãƒˆãƒ¼ãƒ³åˆ†æ ä¸­é–“çµæœ ğŸ¶ ---")
        print(f"å¹³å‡ãƒ”ãƒƒãƒ (å£°ã®é«˜ã•): {pitch_mean:.2f}")
        print(f"å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼ (å£°ã®å¤§ãã•): {rms_mean:.2f}")
        print("-----------------------------------")
        
        # --- â˜…â˜…â˜… ãƒˆãƒ¼ãƒ³åˆ†æã“ã“ã¾ã§ â˜…â˜…â˜… ---
        
        audio_file.seek(0) # Whisperã«æ¸¡ã™ãŸã‚ã«ãƒã‚¤ãƒ³ã‚¿ã‚’æˆ»ã™

        # --- AI â‘ ï¼šWhisperã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã— (æ—¢å­˜ã®å‡¦ç†) ---
        # (ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1",
            file=(audio_file.filename, audio_file.read()),
            language="ja",
            prompt=prompt_text,
            response_format="verbose_json"
        )
        
        # (ä»¥ä¸‹ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
        LOGPROB_THRESHOLD = -1.0
        NO_SPEECH_PROB_THRESHOLD = 0.7
        filtered_text = ""
        for segment in transcript_data.segments:
            avg_logprob = segment.avg_logprob
            no_speech_prob = segment.no_speech_prob
            if avg_logprob < LOGPROB_THRESHOLD or no_speech_prob > NO_SPEECH_PROB_THRESHOLD:
                continue
            filtered_text += segment.text
        
        sentiment_score = 0.0
        is_negative_atmosphere = False
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": filtered_text}
                    ],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                import json
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                sentiment_score = function_args.get("score", 0.0)
                if sentiment_score < -0.3:
                    is_negative_atmosphere = True
            except Exception as e:
                print(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        return jsonify({
            'is_negative': is_negative_atmosphere, 
            'filtered_text': filtered_text,
            'sentiment_score': f"{sentiment_score:.2f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# /correct ãƒ«ãƒ¼ãƒˆã¨ main ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

"""
"""
# app.py (æ€’ã‚Šæ¤œçŸ¥ãƒ­ã‚¸ãƒƒã‚¯æ­è¼‰ç‰ˆ)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass
from pydub import AudioSegment

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- â˜…â˜…â˜… 3ã¤ã®ç‰¹å¾´é‡ã‹ã‚‰ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ã‚ˆã†å¤‰æ›´ â˜…â˜…â˜… ---
def calculate_tone_score(pitch, energy, spectral_centroid):

    # --- ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒ€ã‚¤ãƒ¤ãƒ« ---
    # å–œã³ã®åˆ¤å®šåŸºæº–
    PITCH_JOY_THRESHOLD = 180.0
    ENERGY_JOY_THRESHOLD = 0.04
    # æ€’ã‚Šã®åˆ¤å®šåŸºæº–
    ENERGY_ANGER_THRESHOLD = 0.07  # æ€’ã‚Šã¯ã‚ˆã‚Šå¤§ããªã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¼´ã†
    SPECTRAL_ANGER_THRESHOLD = 2500 # æ€’ã‚Šã®å£°ã¯éŸ¿ããŒé‹­ã„ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒãŒé«˜ã„ï¼‰

    # 1. æ€’ã‚Šã®åˆ¤å®š (å„ªå…ˆåº¦ã‚’é«˜ã)
    if energy > ENERGY_ANGER_THRESHOLD and spectral_centroid > SPECTRAL_ANGER_THRESHOLD:
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå¤§ããã€å£°ãŒé‹­ã„ -> æ€’ã‚Š
        return -0.8 # å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢

    # 2. å–œã³ã®åˆ¤å®š
    elif pitch > PITCH_JOY_THRESHOLD and energy > ENERGY_JOY_THRESHOLD:
        # å£°ãŒé«˜ãã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚‚å¤§ãã„ -> å–œã³
        return 0.7

    # 3. ãã‚Œä»¥å¤–
    else:
        return 0.0

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        # --- ãƒˆãƒ¼ãƒ³åˆ†æå‡¦ç† ---
        webm_filename = "temp_audio.webm"
        audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm")
        wav_filename = "temp_converted.wav"
        sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        
        # 3ã¤ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
        rms = librosa.feature.rms(y=y)
        # â˜…â˜…â˜… ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒã‚’è¿½åŠ  â˜…â˜…â˜…
        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)

        # å¹³å‡å€¤ã‚’è¨ˆç®—
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0
        rms_mean = np.mean(rms)
        spectral_centroid_mean = np.mean(spectral_centroid) # â˜…ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒã®å¹³å‡å€¤

        # â˜… 3ã¤ã®ç‰¹å¾´é‡ã‚’æ¸¡ã—ã¦ãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        tone_score = calculate_tone_score(pitch_mean, rms_mean, spectral_centroid_mean)
        
        print("--- ğŸ¶ ãƒˆãƒ¼ãƒ³åˆ†æ çµæœ ğŸ¶ ---")
        print(f"å¹³å‡ãƒ”ãƒƒãƒ: {pitch_mean:.2f}, å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼: {rms_mean:.2f}, ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ: {spectral_centroid_mean:.2f}")
        print(f"ç®—å‡ºã•ã‚ŒãŸãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢: {tone_score:.2f}")
        print("-----------------------------------")
        
        audio_file.seek(0)

        # (ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨ã‚¹ã‚³ã‚¢çµ±åˆã®éƒ¨åˆ†ã¯å¤‰æ›´ãªã—)
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1", file=(audio_file.filename, audio_file.read()), language="ja", prompt=prompt_text, response_format="verbose_json"
        )
        filtered_text = ""
        for segment in transcript_data.segments:
            if segment.avg_logprob > -1.0 and segment.no_speech_prob < 0.7:
                 filtered_text += segment.text
        text_sentiment_score = 0.0
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": filtered_text}],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                import json
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                text_sentiment_score = function_args.get("score", 0.0)
            except Exception as e:
                print(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        final_score = (text_sentiment_score * 0.7) + (tone_score * 0.3)
        final_score = max(-1.0, min(1.0, final_score))
        print(f"--- ğŸ“Š ã‚¹ã‚³ã‚¢çµ±åˆçµæœ ğŸ“Š ---")
        print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {text_sentiment_score:.2f}, ãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢: {tone_score:.2f}, æœ€çµ‚ã‚¹ã‚³ã‚¢: {final_score:.2f}")
        print("-----------------------------")
        is_negative_atmosphere = True if final_score < -0.3 else False
        return jsonify({
            'is_negative': is_negative_atmosphere, 
            'filtered_text': filtered_text,
            'text_score': f"{text_sentiment_score:.2f}",
            'tone_score': f"{tone_score:.2f}",
            'final_score': f"{final_score:.2f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# /correct ãƒ«ãƒ¼ãƒˆã¯å¤‰æ›´ãªã—
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

"""
"""
# app.py (æ­£è¦åŒ–ï¼‹ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ­è¼‰ æœ€çµ‚å½¢æ…‹)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass
from pydub import AudioSegment

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- â˜…â˜…â˜… æ­£è¦åŒ–ã¨ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚’èåˆã•ã›ãŸæœ€çµ‚ç‰ˆã®é–¢æ•° â˜…â˜…â˜… ---
def calculate_tone_score(pitch, energy, spectral_centroid):

    # --- ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒ€ã‚¤ãƒ¤ãƒ« (æ­£è¦åŒ–ã®ãŸã‚ã®åŸºæº–å€¤) ---
    PITCH_MIN, PITCH_MAX = 85.0, 255.0
    ENERGY_MIN, ENERGY_MAX = 0.005, 0.15
    SPECTRAL_MIN, SPECTRAL_MAX = 500.0, 3500.0

    # 1. å„ç‰¹å¾´é‡ã‚’ 0.0 ~ 1.0 ã®ç¯„å›²ã«æ­£è¦åŒ–
    norm_pitch = (np.clip(pitch, PITCH_MIN, PITCH_MAX) - PITCH_MIN) / (PITCH_MAX - PITCH_MIN)
    norm_energy = (np.clip(energy, ENERGY_MIN, ENERGY_MAX) - ENERGY_MIN) / (ENERGY_MAX - ENERGY_MIN)
    norm_sharpness = (np.clip(spectral_centroid, SPECTRAL_MIN, SPECTRAL_MAX) - SPECTRAL_MIN) / (SPECTRAL_MAX - SPECTRAL_MIN)

    # 2. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¤å®š (å„ªå…ˆ)
    # æ€’ã‚Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒéå¸¸ã«é«˜ã(ä¸Šä½20%)ã€ã‹ã¤ã€å£°ãŒéå¸¸ã«é‹­ã„(ä¸Šä½20%)
    if norm_energy > 0.8 and norm_sharpness > 0.8:
        return -0.8  # å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢ã‚’è¿”ã™

    # å–œã³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒé«˜ã(ä¸Šä½30%)ã€ã‹ã¤ã€ãƒ”ãƒƒãƒã‚‚é«˜ã„(ä¸Šä½30%)
    elif norm_energy > 0.7 and norm_pitch > 0.7:
        return 0.7  # å¼·ã„ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢ã‚’è¿”ã™

    # 3. ä¸Šè¨˜ã®ç‰¹æ®Šãªãƒ‘ã‚¿ãƒ¼ãƒ³ä»¥å¤–ã¯ã€æ»‘ã‚‰ã‹ãªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    else:
        # æ­£è¦åŒ–ã•ã‚ŒãŸå€¤ã‚’ -1.0 ~ 1.0 ã®ã‚¹ã‚³ã‚¢ã«å¤‰æ›
        pitch_score = (norm_pitch - 0.5) * 2
        energy_score = (norm_energy - 0.5) * 2
        
        # ãƒ”ãƒƒãƒã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å¹³å‡ã‚’åŸºæœ¬çš„ãªãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹
        base_score = (pitch_score + energy_score) / 2.0
        return base_score

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    audio_file = request.files['audio']
    if audio_file.filename == '': return jsonify({'error': 'No selected file'}), 400

    try:
        # --- ãƒˆãƒ¼ãƒ³åˆ†æå‡¦ç† ---
        webm_filename = "temp_audio.webm"
        audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm")
        wav_filename = "temp_converted.wav"
        sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        
        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
        rms = librosa.feature.rms(y=y)
        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0
        rms_mean = np.mean(rms)
        spectral_centroid_mean = np.mean(spectral_centroid)
        
        # æœ€çµ‚ç‰ˆã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        tone_score = calculate_tone_score(pitch_mean, rms_mean, spectral_centroid_mean)
        
        print("--- ğŸ¶ ãƒˆãƒ¼ãƒ³åˆ†æ çµæœ ğŸ¶ ---")
        print(f"å¹³å‡ãƒ”ãƒƒãƒ: {pitch_mean:.2f}, å¹³å‡ã‚¨ãƒãƒ«ã‚®ãƒ¼: {rms_mean:.2f}, ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒ: {spectral_centroid_mean:.2f}")
        print(f"ç®—å‡ºã•ã‚ŒãŸãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢: {tone_score:.2f}")
        print("-----------------------------------")
        
        audio_file.seek(0)

        # --- ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨ã‚¹ã‚³ã‚¢çµ±åˆ (å¤‰æ›´ãªã—) ---
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1", file=(audio_file.filename, audio_file.read()), language="ja", prompt=prompt_text, response_format="verbose_json"
        )
        filtered_text = ""
        for segment in transcript_data.segments:
            if segment.avg_logprob > -1.0 and segment.no_speech_prob < 0.7:
                 filtered_text += segment.text
        text_sentiment_score = 0.0
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": filtered_text}],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                import json
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                text_sentiment_score = function_args.get("score", 0.0)
            except Exception as e:
                print(f"æ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        final_score = (text_sentiment_score * 0.7) + (tone_score * 0.3)
        final_score = max(-1.0, min(1.0, final_score))
        print(f"--- ğŸ“Š ã‚¹ã‚³ã‚¢çµ±åˆçµæœ ğŸ“Š ---")
        print(f"ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {text_sentiment_score:.2f}, ãƒˆãƒ¼ãƒ³ã‚¹ã‚³ã‚¢: {tone_score:.2f}, æœ€çµ‚ã‚¹ã‚³ã‚¢: {final_score:.2f}")
        print("-----------------------------")
        is_negative_atmosphere = True if final_score < -0.3 else False

        return jsonify({
            'is_negative': is_negative_atmosphere, 
            'filtered_text': filtered_text,
            'text_score': f"{text_sentiment_score:.2f}",
            'tone_score': f"{tone_score:.2f}",
            'final_score': f"{final_score:.2f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

# /correct ãƒ«ãƒ¼ãƒˆã¨ main ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“
@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
"""
"""
# app.py (çœç•¥ä¸€åˆ‡ãªã—ãƒ»æœ€çµ‚å®Œæˆç‰ˆ)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass
from pydub import AudioSegment
import json

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
emotion_dictionary = {}
normalization_ranges = {}

def _calculate_normalization_ranges():
    æ„Ÿæƒ…è¾æ›¸ã‹ã‚‰æ­£è¦åŒ–ã®ãŸã‚ã®æœ€å°å€¤ãƒ»æœ€å¤§å€¤ã‚’è¨ˆç®—ã™ã‚‹
    global normalization_ranges
    
    if len(emotion_dictionary) < 4:
        return

    pitches = [vec[0] for vec in emotion_dictionary.values()]
    energies = [vec[1] for vec in emotion_dictionary.values()]
    sharpnesses = [vec[2] for vec in emotion_dictionary.values()]

    # å€¤ãŒä¸€ã¤ã—ã‹ãªã„å ´åˆã«ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ããŸã‚ã€å°‘ã—å¹…ã‚’æŒãŸã›ã‚‹
    def get_range(values):
        min_val, max_val = min(values), max(values)
        if min_val == max_val:
            return {'min': min_val * 0.9, 'max': max_val * 1.1}
        return {'min': min_val, 'max': max_val}

    normalization_ranges = {
        'pitch': get_range(pitches),
        'energy': get_range(energies),
        'sharpness': get_range(sharpnesses)
    }
    print("--- æ­£è¦åŒ–ãƒ¬ãƒ³ã‚¸ã‚’è¨ˆç®—ã—ã¾ã—ãŸ ---")
    print(normalization_ranges)
    print("------------------------------------------------")

def calculate_personalized_score(pitch, energy, sharpness, ranges):

    if not ranges:
        return 0.0

    def normalize(value, r):
        # 0é™¤ç®—ã‚’é¿ã‘ã‚‹
        if (r['max'] - r['min']) == 0:
            return 0.5
        return (np.clip(value, r['min'], r['max']) - r['min']) / (r['max'] - r['min'])

    norm_pitch = normalize(pitch, ranges['pitch'])
    norm_energy = normalize(energy, ranges['energy'])
    norm_sharpness = normalize(sharpness, ranges['sharpness'])

    if norm_energy > 0.8 and norm_sharpness > 0.8:
        return -0.8
    elif norm_energy > 0.7 and norm_pitch > 0.7:
        return 0.7
    else:
        pitch_score = (norm_pitch - 0.5) * 2
        energy_score = (norm_energy - 0.5) * 2
        return (pitch_score + energy_score) / 2.0

@app.route('/calibrate', methods=['POST'])
def calibrate_emotion():
    if 'audio' not in request.files: return jsonify({'status': 'error', 'error': 'No audio file part'}), 400
    emotion = request.args.get('emotion')
    if not emotion: return jsonify({'status': 'error', 'error': 'Emotion label is missing'}), 400
    audio_file = request.files['audio']
    try:
        webm_filename = f"temp_{emotion}.webm"
        audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm")
        wav_filename = f"temp_{emotion}.wav"
        sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        
        pitches, _ = librosa.piptrack(y=y, sr=sr)
        rms = librosa.feature.rms(y=y)
        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0
        rms_mean = np.mean(rms)
        spectral_centroid_mean = np.mean(spectral_centroid)
        
        emotion_dictionary[emotion] = [pitch_mean, rms_mean, spectral_centroid_mean]
        
        if len(emotion_dictionary) == 4:
            _calculate_normalization_ranges()

        return jsonify({'status': 'success', 'emotion': emotion})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    if not normalization_ranges:
        return jsonify({'error': 'èª¿æ•´ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“ã€‚å…¨ã¦ã®æ„Ÿæƒ…ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚'})

    audio_file = request.files['audio']
    try:
        webm_filename = "temp_audio.webm"
        audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm")
        wav_filename = "temp_converted.wav"
        sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        
        pitches, _ = librosa.piptrack(y=y, sr=sr)
        rms = librosa.feature.rms(y=y)
        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        
        current_features = [
            np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0,
            np.mean(rms),
            np.mean(spectral_centroid)
        ]
        
        tone_score = calculate_personalized_score(current_features[0], current_features[1], current_features[2], normalization_ranges)
        
        audio_file.seek(0)
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(
            model="whisper-1", file=(audio_file.filename, audio_file.read()), language="ja", prompt=prompt_text, response_format="verbose_json"
        )
        
        filtered_text = ""
        for segment in transcript_data.segments:
            if segment.avg_logprob > -1.0 and segment.no_speech_prob < 0.7:
                 filtered_text += segment.text
        
        text_sentiment_score = 0.0
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": filtered_text}
                    ],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                text_sentiment_score = function_args.get("score", 0.0)
            except Exception as e:
                print(f"GPTæ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        final_score = (text_sentiment_score * 0.7) + (tone_score * 0.3)
        final_score = max(-1.0, min(1.0, final_score))
        
        return jsonify({
            'is_negative': True if final_score < -0.3 else False, 
            'filtered_text': filtered_text,
            'text_score': f"{text_sentiment_score:.2f}",
            'tone_score': f"{tone_score:.2f}",
            'final_score': f"{final_score:.2f}"
        })

    except Exception as e:
        print(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": original_text}
            ]
        )
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
"""
"""
# app.py (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰æ­è¼‰ãƒ»æœ€çµ‚ç‰ˆ)
import os
import math
import librosa
import numpy as np
from openai import OpenAI
from flask import Flask, request, jsonify, render_template
from getpass import getpass
from pydub import AudioSegment
import json

app = Flask(__name__)

try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
emotion_dictionary = {}
normalization_ranges = {}

def _calculate_normalization_ranges():
    global normalization_ranges
    if len(emotion_dictionary) < 4:
        return
    pitches = [vec[0] for vec in emotion_dictionary.values()]
    energies = [vec[1] for vec in emotion_dictionary.values()]
    sharpnesses = [vec[2] for vec in emotion_dictionary.values()]
    def get_range(values):
        min_val, max_val = min(values), max(values)
        if min_val == max_val:
            return {'min': min_val * 0.9, 'max': max_val * 1.1}
        return {'min': min_val, 'max': max_val}
    normalization_ranges = {
        'pitch': get_range(pitches),
        'energy': get_range(energies),
        'sharpness': get_range(sharpnesses)
    }
    print("--- ğŸ§  ã‚ãªãŸå°‚ç”¨ã®æ­£è¦åŒ–ãƒ¬ãƒ³ã‚¸ã‚’è¨ˆç®—ã—ã¾ã—ãŸ ---")
    print(normalization_ranges)

# â˜…â˜…â˜… é–¢æ•°åã‚’ã‚ˆã‚Šæ±ç”¨çš„ã«å¤‰æ›´ â˜…â˜…â˜…
def calculate_tone_score(pitch, energy, sharpness, ranges):
    if not ranges:
        return 0.0
    def normalize(value, r):
        if (r['max'] - r['min']) == 0: return 0.5
        return (np.clip(value, r['min'], r['max']) - r['min']) / (r['max'] - r['min'])
    norm_pitch = normalize(pitch, ranges['pitch'])
    norm_energy = normalize(energy, ranges['energy'])
    norm_sharpness = normalize(sharpness, ranges['sharpness'])
    if norm_energy > 0.8 and norm_sharpness > 0.8: return -0.8
    elif norm_energy > 0.7 and norm_pitch > 0.7: return 0.7
    else:
        pitch_score = (norm_pitch - 0.5) * 2
        energy_score = (norm_energy - 0.5) * 2
        return (pitch_score + energy_score) / 2.0

@app.route('/calibrate', methods=['POST'])
def calibrate_emotion():
    # (ã“ã®é–¢æ•°ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
    emotion = request.args.get('emotion')
    audio_file = request.files['audio']
    try:
        webm_filename = f"temp_{emotion}.webm"; audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm"); wav_filename = f"temp_{emotion}.wav"; sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        pitches, _ = librosa.piptrack(y=y, sr=sr); rms = librosa.feature.rms(y=y); spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0; rms_mean = np.mean(rms); spectral_centroid_mean = np.mean(spectral_centroid)
        emotion_dictionary[emotion] = [pitch_mean, rms_mean, spectral_centroid_mean]
        if len(emotion_dictionary) == 4:
            _calculate_normalization_ranges()
        return jsonify({'status': 'success', 'emotion': emotion})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']
    try:
        # â˜…â˜…â˜… ã“ã“ã‹ã‚‰ãŒãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åŒ–ã®ã‚­ãƒ¢ â˜…â˜…â˜…
        active_ranges = {}
        if normalization_ranges: # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
            # å®Œäº†ã—ã¦ã„ã‚‹ -> ã‚ãªãŸå°‚ç”¨ã®ç‰©å·®ã—ã‚’ä½¿ã†
            active_ranges = normalization_ranges
            print("ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºè¨­å®šã§åˆ†æä¸­...")
        else:
            # æœªå®Œäº† -> ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç‰©å·®ã—ã‚’ä½¿ã†
            active_ranges = {
                'pitch': {'min': 85.0, 'max': 255.0},
                'energy': {'min': 0.005, 'max': 0.15},
                'sharpness': {'min': 500.0, 'max': 3500.0}
            }
            print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§åˆ†æä¸­...")
        # â˜…â˜…â˜… ã“ã“ã¾ã§ â˜…â˜…â˜…

        # (ç‰¹å¾´é‡æŠ½å‡ºã®ã‚³ãƒ¼ãƒ‰ã¯åŒã˜)
        webm_filename = "temp_audio.webm"; audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm"); wav_filename = "temp_converted.wav"; sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        pitches, _ = librosa.piptrack(y=y, sr=sr); rms = librosa.feature.rms(y=y); spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        current_features = [
            np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0,
            np.mean(rms),
            np.mean(spectral_centroid)
        ]
        
        # é¸æŠã•ã‚ŒãŸç‰©å·®ã—(active_ranges)ã‚’ä½¿ã£ã¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        tone_score = calculate_tone_score(current_features[0], current_features[1], current_features[2], active_ranges)
        
        # (ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã¨ã‚¹ã‚³ã‚¢çµ±åˆã€çµæœè¿”å´ã®éƒ¨åˆ†ã¯å¤‰æ›´ãªã—)
        audio_file.seek(0)
        prompt_text = request.form.get('prompt', '')
        transcript_data = client.audio.transcriptions.create(model="whisper-1", file=(audio_file.filename, audio_file.read()), language="ja", prompt=prompt_text, response_format="verbose_json")
        filtered_text = ""
        for segment in transcript_data.segments:
            if segment.avg_logprob > -1.0 and segment.no_speech_prob < 0.7: filtered_text += segment.text
        text_sentiment_score = 0.0
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": filtered_text}],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                text_sentiment_score = function_args.get("score", 0.0)
            except Exception as e:
                print(f"GPTæ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        final_score = (text_sentiment_score * 0.7) + (tone_score * 0.3)
        final_score = max(-1.0, min(1.0, final_score))
        return jsonify({
            'is_negative': True if final_score < -0.3 else False, 
            'filtered_text': filtered_text,
            'text_score': f"{text_sentiment_score:.2f}",
            'tone_score': f"{tone_score:.2f}",
            'final_score': f"{final_score:.2f}"
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    data = request.json
    if not data or 'text' not in data: return jsonify({'error': 'No text provided.'}), 400
    original_text = data['text']
    try:
        response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": original_text}])
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
"""

# app.py (å°å­¦ç”Ÿã§ã‚‚ã‚ã‹ã‚‹è§£èª¬ã‚³ãƒ¡ãƒ³ãƒˆä»˜ã)

# ------------------------------------------------
# â‘  ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆé“å…·ã®æº–å‚™ï¼‰
# ------------------------------------------------
# ã“ã‚Œã‹ã‚‰ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œã‚‹ãŸã‚ã«ã€ä¾¿åˆ©ãªé“å…·ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã‚’æƒãˆã¾ã™ã€‚
import os  # PCã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ“ä½œã™ã‚‹ãŸã‚ã®é“å…·
import math  # é›£ã—ã„è¨ˆç®—ã‚’ã™ã‚‹ãŸã‚ã®ç®—æ•°ã®é“å…·
import librosa  # éŸ³ã®åšå£«ã€‚å£°ã®ç‰¹å¾´ã‚’åˆ†æã—ã¦ãã‚Œã‚‹
import numpy as np  # è¨ˆç®—ãŒå¾—æ„ãªç®—æ•°ã®é“å…·ï¼ˆè¡Œåˆ—ã¨ã‹ã‚’æ‰±ãˆã‚‹ï¼‰
from openai import OpenAI  # OpenAIç¤¾ã®AIã¨è©±ã™ãŸã‚ã®é›»è©±
from flask import Flask, request, jsonify, render_template  # Webã‚µã‚¤ãƒˆã‚’ä½œã‚‹ãŸã‚ã®è¨­è¨ˆå›³ã‚„éƒ¨å“
from getpass import getpass  # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãªã©ã‚’å®‰å…¨ã«å…¥åŠ›ã™ã‚‹ãŸã‚ã®é“å…·
from pydub import AudioSegment  # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã™ã‚‹ãŸã‚ã®é“å…·
import json  # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ã™ã‚‹ãŸã‚ã®é“å…·

# ------------------------------------------------
# â‘¡ åˆæœŸè¨­å®šï¼ˆä¸‹æº–å‚™ï¼‰
# ------------------------------------------------
# ã“ã‚Œã‹ã‚‰Flaskã§Webã‚¢ãƒ—ãƒªã‚’ä½œã‚Šã¾ã™ã‚ˆã€ã¨ã„ã†åˆå›³
app = Flask(__name__)

# OpenAIã®AIã¨è©±ã™ãŸã‚ã®é›»è©±ã‚’æº–å‚™ã—ã¾ã™ã€‚APIã‚­ãƒ¼ã¨ã„ã†ç§˜å¯†ã®åˆè¨€è‘‰ãŒå¿…è¦ã§ã™ã€‚
try:
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY") or getpass("Please enter your OpenAI API Key: "))
except Exception as e:
    client = None
    print(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã§ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã®ä¿ç®¡å ´æ‰€ï¼‰ ---
# ã€Œå£°ã®æ„Ÿæƒ…è¾æ›¸ã€ã‚’ã—ã¾ã†ãŸã‚ã®ã€ç©ºã£ã½ã®æœ¬æ£šã‚’æº–å‚™ã—ã¾ã™ã€‚
emotion_dictionary = {}
# ã€Œã‚ãªãŸå°‚ç”¨ã®ã‚‚ã®ã•ã—ã€ã‚’ã—ã¾ã†ãŸã‚ã®ã€ç©ºã£ã½ã®é“å…·ç®±ã‚’æº–å‚™ã—ã¾ã™ã€‚
normalization_ranges = {}


# ------------------------------------------------
# â‘¢ é–¢æ•°ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®éƒ¨å“ï¼‰ã®å®šç¾©
# ------------------------------------------------

def _calculate_normalization_ranges():
    """
    4ã¤ã®æ„Ÿæƒ…ã‚µãƒ³ãƒ—ãƒ«ãŒé›†ã¾ã£ãŸã‚‰ã€ã‚ãªãŸã ã‘ã®ã€Œå£°ã®ã‚‚ã®ã•ã—ã€ã‚’ä½œã‚‹é–¢æ•°ã€‚
    """
    global normalization_ranges  # é“å…·ç®±ã‚’æ“ä½œã—ã¾ã™ã‚ˆã€ã¨ã„ã†å®£è¨€
    
    if len(emotion_dictionary) < 4:
        return # ã¾ã 4ã¤æƒã£ã¦ãªã‘ã‚Œã°ä½•ã‚‚ã—ãªã„

    # æœ¬æ£šï¼ˆæ„Ÿæƒ…è¾æ›¸ï¼‰ã‹ã‚‰ã€ãã‚Œãã‚Œã®æ„Ÿæƒ…ã®ã€Œé«˜ã•ã€ã€Œå¤§ãã•ã€ã€Œé‹­ã•ã€ã®æ•°å€¤ã‚’å…¨éƒ¨å–ã‚Šå‡ºã™
    pitches = [vec[0] for vec in emotion_dictionary.values()]
    energies = [vec[1] for vec in emotion_dictionary.values()]
    sharpnesses = [vec[2] for vec in emotion_dictionary.values()]

    # ä¸€ç•ªå°ã•ã„æ•°å€¤ã¨å¤§ãã„æ•°å€¤ã‚’è¦‹ã¤ã‘ã¦ã€å£°ã®ã€Œæœ€ä½éŸ³ã€ã¨ã€Œæœ€é«˜éŸ³ã€ã®ç¯„å›²ã‚’æ±ºã‚ã‚‹
    def get_range(values):
        min_val, max_val = min(values), max(values)
        if min_val == max_val: # ã‚‚ã—å…¨éƒ¨åŒã˜ã ã£ãŸã‚‰ã€å°‘ã—ã ã‘ç¯„å›²ã‚’åºƒã’ã¦ãŠã
            return {'min': min_val * 0.9, 'max': max_val * 1.1}
        return {'min': min_val, 'max': max_val}

    # è¨ˆç®—ã—ãŸã€Œã‚ãªãŸå°‚ç”¨ã®ã‚‚ã®ã•ã—ã€ã‚’é“å…·ç®±ã«ã—ã¾ã†
    normalization_ranges = {
        'pitch': get_range(pitches),
        'energy': get_range(energies),
        'sharpness': get_range(sharpnesses)
    }
    print("--- ğŸ§  ã‚ãªãŸå°‚ç”¨ã®æ­£è¦åŒ–ãƒ¬ãƒ³ã‚¸ï¼ˆã‚‚ã®ã•ã—ï¼‰ã‚’è¨ˆç®—ã—ã¾ã—ãŸ ---")
    print(normalization_ranges)


def calculate_tone_score(pitch, energy, sharpness, ranges):
    """
    å£°ã®ãƒˆãƒ¼ãƒ³ã‹ã‚‰ã€ä»Šã®æ°—æŒã¡ã‚’ç‚¹æ•°ã«ã™ã‚‹ã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã®å¿ƒè‡“éƒ¨ã®ä¸€ã¤ã€‚
    """
    if not ranges:
        return 0.0 # ã¾ã ã‚‚ã®ã•ã—ãŒãªã‘ã‚Œã°0ç‚¹

    # ã©ã‚“ãªå£°ã§ã‚‚0ç‚¹ã‹ã‚‰1ç‚¹ã®é–“ã®ç‚¹æ•°ã«å¤‰æ›ã™ã‚‹ã€Œã‚‚ã®ã•ã—ã€æ©Ÿèƒ½
    def normalize(value, r):
        if (r['max'] - r['min']) == 0: return 0.5
        # ã€Œä»Šã®å£° - ã‚ãªãŸã®æœ€ä½éŸ³) / (ã‚ãªãŸã®æœ€é«˜éŸ³ - ã‚ãªãŸã®æœ€ä½éŸ³)ã€ã¨ã„ã†è¨ˆç®—
        return (np.clip(value, r['min'], r['max']) - r['min']) / (r['max'] - r['min'])

    # 3ã¤ã®ç‰¹å¾´ã‚’ã€ãã‚Œãã‚Œ0ã€œ1ç‚¹ã®ç‚¹æ•°ã«å¤‰æ›ã™ã‚‹
    norm_pitch = normalize(pitch, ranges['pitch'])
    norm_energy = normalize(energy, ranges['energy'])
    norm_sharpness = normalize(sharpness, ranges['sharpness'])

    # --- ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ç‚¹æ•°ã‚’æ±ºã‚ã‚‹ ---
    # ã‚‚ã—å£°ã®å¤§ãã•ã¨é‹­ã•ãŒMAXã«è¿‘ã‹ã£ãŸã‚‰ï¼ˆã‚ãªãŸã®å£°ã®80%ä»¥ä¸Šãªã‚‰ï¼‰ã€ã€Œæ€’ã‚Šã€ã¨åˆ¤æ–­ã—ã¦ãƒã‚¤ãƒŠã‚¹80ç‚¹ï¼
    if norm_energy > 0.8 and norm_sharpness > 0.8: return -0.8
    # ã‚‚ã—å£°ã®å¤§ãã•ã¨é«˜ã•ãŒã™ã”ãé«˜ã‹ã£ãŸã‚‰ï¼ˆã‚ãªãŸã®å£°ã®70%ä»¥ä¸Šãªã‚‰ï¼‰ã€ã€Œå–œã³ã€ã¨åˆ¤æ–­ã—ã¦ãƒ—ãƒ©ã‚¹70ç‚¹ï¼
    elif norm_energy > 0.7 and norm_pitch > 0.7: return 0.7
    # ãã‚Œä»¥å¤–ã®æ™®é€šã®å£°ã®ã¨ãã¯ã€-100ç‚¹ã‹ã‚‰+100ç‚¹ã®é–“ã®æ»‘ã‚‰ã‹ãªç‚¹æ•°ã‚’ã¤ã‘ã‚‹
    else:
        pitch_score = (norm_pitch - 0.5) * 2
        energy_score = (norm_energy - 0.5) * 2
        return (pitch_score + energy_score) / 2.0

# ------------------------------------------------
# â‘£ Flaskã®ãƒ«ãƒ¼ãƒˆï¼ˆWebã‚µã‚¤ãƒˆã®ãƒšãƒ¼ã‚¸ã‚„æ©Ÿèƒ½ï¼‰ã®å®šç¾©
# ------------------------------------------------

@app.route('/calibrate', methods=['POST'])
def calibrate_emotion():
    """
    ãƒ–ãƒ©ã‚¦ã‚¶ã®ã€Œã€‡ã€‡ã‚’éŒ²éŸ³ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«å‹•ãã€ã‚µãƒ¼ãƒãƒ¼ã®å—ä»˜çª“å£ã€‚
    """
    # ã©ã®æ„Ÿæƒ…ã®ã€ã©ã®å£°ã‹ã‚’æ•™ãˆã¦ã‚‚ã‚‰ã†
    emotion = request.args.get('emotion')
    audio_file = request.files['audio']
    try:
        # éŸ³å£°ã‚’åˆ†æã—ã‚„ã™ã„å½¢(.wav)ã«å¤‰æ›ã™ã‚‹
        webm_filename = f"temp_{emotion}.webm"; audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm"); wav_filename = f"temp_{emotion}.wav"; sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        
        # éŸ³ã®åšå£«ï¼ˆlibrosaï¼‰ã«å£°ã®ã€Œé«˜ã•ã€ã€Œå¤§ãã•ã€ã€Œé‹­ã•ã€ã‚’èª¿ã¹ã¦ã‚‚ã‚‰ã†
        pitches, _ = librosa.piptrack(y=y, sr=sr); rms = librosa.feature.rms(y=y); spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0; rms_mean = np.mean(rms); spectral_centroid_mean = np.mean(spectral_centroid)
        
        # èª¿ã¹ãŸçµæœã‚’ãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹
        emotion_dictionary[emotion] = [pitch_mean, rms_mean, spectral_centroid_mean]
        
        # ã‚‚ã—4ã¤ã®æ„Ÿæƒ…ãŒå…¨éƒ¨é›†ã¾ã£ãŸã‚‰ã€ã€Œã‚‚ã®ã•ã—ä½œã‚Šã€ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™
        if len(emotion_dictionary) == 4:
            _calculate_normalization_ranges()

        # ãƒ–ãƒ©ã‚¦ã‚¶ã«ã€ŒæˆåŠŸã—ã¾ã—ãŸï¼ã€ã¨ä¼ãˆã‚‹
        return jsonify({'status': 'success', 'emotion': emotion})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/')
def index():
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€åˆã«ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸã¨ãã«ã€ãƒ¡ã‚¤ãƒ³ã®Webãƒšãƒ¼ã‚¸ï¼ˆindex.htmlï¼‰ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
    """
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_audio():
    """
    ã€Œåˆ†æé–‹å§‹ã€ã®ã‚ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãšã£ã¨å‹•ãç¶šã‘ã‚‹ã€ãƒ¡ã‚¤ãƒ³ã®åˆ†æå·¥å ´ã€‚
    """
    # å¿…è¦ãªã‚‚ã®ãŒæƒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if not client: return jsonify({'error': 'OpenAI client is not configured.'}), 500
    if 'audio' not in request.files: return jsonify({'error': 'No audio file part'}), 400
    
    audio_file = request.files['audio']
    try:
        # --- ãƒˆãƒ¼ãƒ³åˆ†æã®æº–å‚™ ---
        # ã‚‚ã—ã€Œã‚ãªãŸå°‚ç”¨ã®ã‚‚ã®ã•ã—ã€ãŒå®Œæˆã—ã¦ã„ãŸã‚‰ãã‚Œã‚’ä½¿ã†ã€‚ã¾ã ãªã‚‰ã€Œã¿ã‚“ãªç”¨ã®ã‚‚ã®ã•ã—ã€ã‚’ä½¿ã†ã€‚
        active_ranges = {}
        if normalization_ranges:
            active_ranges = normalization_ranges
            print("ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºè¨­å®šã§åˆ†æä¸­...")
        else:
            active_ranges = {
                'pitch': {'min': 85.0, 'max': 255.0},
                'energy': {'min': 0.005, 'max': 0.15},
                'sharpness': {'min': 500.0, 'max': 3500.0}
            }
            print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§åˆ†æä¸­...")

        # --- ãƒˆãƒ¼ãƒ³åˆ†æã®å®Ÿè¡Œ ---
        # ä»Šã€è©±ã—ã¦ã„ã‚‹å£°ã®ç‰¹å¾´ã‚’èª¿ã¹ã‚‹
        webm_filename = "temp_audio.webm"; audio_file.save(webm_filename)
        sound = AudioSegment.from_file(webm_filename, format="webm"); wav_filename = "temp_converted.wav"; sound.export(wav_filename, format="wav")
        y, sr = librosa.load(wav_filename)
        pitches, _ = librosa.piptrack(y=y, sr=sr); rms = librosa.feature.rms(y=y); spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
        current_features = [np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0.0, np.mean(rms), np.mean(spectral_centroid)]
        
        # èª¿ã¹ãŸç‰¹å¾´ã¨ä½¿ã†ã€Œã‚‚ã®ã•ã—ã€ã‚’æ¸¡ã—ã¦ã€ãƒˆãƒ¼ãƒ³ã®ç‚¹æ•°ã‚’å‡ºã—ã¦ã‚‚ã‚‰ã†
        tone_score = calculate_tone_score(current_features[0], current_features[1], current_features[2], active_ranges)
        
        # --- ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®å®Ÿè¡Œ ---
        audio_file.seek(0)
        prompt_text = request.form.get('prompt', '')
        # AIé›»è©±ã§Whisperã‚’å‘¼ã³å‡ºã—ã€éŸ³å£°ã‚’æ–‡å­—ã«ã—ã¦ã‚‚ã‚‰ã†
        transcript_data = client.audio.transcriptions.create(model="whisper-1", file=(audio_file.filename, audio_file.read()), language="ja", prompt=prompt_text, response_format="verbose_json")
        
        # AIã®å¹»è´ã‚„è‡ªä¿¡ã®ãªã„è¨€è‘‰ã‚’æ¨ã¦ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        filtered_text = ""
        for segment in transcript_data.segments:
            if segment.avg_logprob > -1.0 and segment.no_speech_prob < 0.7: filtered_text += segment.text
        
        # AIé›»è©±ã§ä»Šåº¦ã¯GPTã‚’å‘¼ã³å‡ºã—ã€æ–‡ç« ã®æ„å‘³ã‹ã‚‰æ°—æŒã¡ã‚’ç‚¹æ•°ã«ã—ã¦ã‚‚ã‚‰ã†
        text_sentiment_score = 0.0
        if filtered_text.strip():
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‹ã‚’åˆ¤æ–­ã—ã€-1.0ï¼ˆå®Œå…¨ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆå®Œå…¨ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": filtered_text}],
                    functions=[{"name": "set_sentiment_score","description": "æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨­å®šã™ã‚‹","parameters": {"type": "object","properties": {"score": {"type": "number","description": "æ„Ÿæƒ…ã‚¹ã‚³ã‚¢, -1.0ã‹ã‚‰1.0"}},"required": ["score"]}}],
                    function_call={"name": "set_sentiment_score"}
                )
                function_args = json.loads(response.choices[0].message.function_call.arguments)
                text_sentiment_score = function_args.get("score", 0.0)
            except Exception as e:
                print(f"GPTæ„Ÿæƒ…åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
        # --- æœ€çµ‚çµæœã®è¨ˆç®—ã¨è¿”å´ ---
        # ã€Œè¨€è‘‰ã®ç‚¹æ•°ã€ã¨ã€Œãƒˆãƒ¼ãƒ³ã®ç‚¹æ•°ã€ã‚’åˆä½“ã•ã›ã¦ã€æœ€çµ‚çš„ãªç‚¹æ•°ã‚’æ±ºã‚ã‚‹
        final_score = (text_sentiment_score * 0.7) + (tone_score * 0.3)
        final_score = max(-1.0, min(1.0, final_score)) # ç‚¹æ•°ãŒ-100ã€œ+100ç‚¹ã«åã¾ã‚‹ã‚ˆã†ã«èª¿æ•´
        
        # è¨ˆç®—ã—ãŸã™ã¹ã¦ã®çµæœã‚’ã€ãƒ–ãƒ©ã‚¦ã‚¶ã«é€ã‚Šè¿”ã™
        return jsonify({
            'is_negative': True if final_score < -0.3 else False, 
            'filtered_text': filtered_text,
            'text_score': f"{text_sentiment_score:.2f}",
            'tone_score': f"{tone_score:.2f}",
            'final_score': f"{final_score:.2f}"
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/correct', methods=['POST'])
def correct_text_with_llm():
    """
    ã€ŒLLMã§æ ¡æ­£ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«å‹•ãã€ç‰¹åˆ¥ãªå—ä»˜çª“å£ã€‚
    """
    # GPTã«ã€Œãƒ—ãƒ­ã®ç·¨é›†è€…ã«ãªã£ã¦ã€ã¨ãŠé¡˜ã„ã—ã¦ã€è­°äº‹éŒ²å…¨ä½“ã‚’ã‚­ãƒ¬ã‚¤ãªæ–‡ç« ã«ç›´ã—ã¦ã‚‚ã‚‰ã†
    original_text = request.json['text']
    try:
        response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ä¼šè­°ã®è­°äº‹éŒ²ã‚’æ ¡æ­£ã™ã‚‹ãƒ—ãƒ­ã®æ›¸è¨˜ã§ã™ã€‚èª¤å­—è„±å­—ã‚’ä¿®æ­£ã—ã€æ–‡è„ˆã¨ã—ã¦ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’ä¿®æ­£ã—ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã®è­°äº‹éŒ²ã«æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚"},{"role": "user", "content": original_text}])
        corrected_text = response.choices[0].message.content
        return jsonify({'corrected_text': corrected_text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ------------------------------------------------
# â‘¤ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®èµ·å‹•
# ------------------------------------------------
if __name__ == '__main__':
    from waitress import serve
    # æœ¬ç•ªç’°å¢ƒã§ã¯ debug=True ã¯ä½¿ã‚ãªã„
    serve(app, host="0.0.0.0", port=8080)